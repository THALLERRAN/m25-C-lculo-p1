{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo - Tarefa 01\n",
    "\n",
    "1. Marque quais desses métodos/algoritmos muito populares em ciência de dados são baseados no uso de derivada:\n",
    "\n",
    "    1. Método Mínimos Quadrados\n",
    "    2. Gradiente descendente\n",
    "    3. Newton Raphson\n",
    "    4. CART (Árvore de decisão)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅Método Mínimos Quadrados\n",
    "Este método é usado principalmente em regressão linear para encontrar a linha que melhor se ajusta aos dados. O objetivo é minimizar a soma dos quadrados dos erros (a diferença entre o valor real e o valor previsto). Para encontrar o ponto de mínimo dessa função de erro, calculamos suas derivadas parciais em relação a cada coeficiente do modelo e as igualamos a zero. Resolver esse sistema de equações nos dá os coeficientes ideais.\n",
    "\n",
    "✅ Gradiente Descendente (Gradient Descent)\n",
    "É um dos algoritmos de otimização mais importantes em machine learning. Seu objetivo é encontrar o mínimo de uma função (geralmente uma função de custo/perda). Ele faz isso calculando o gradiente da função no ponto atual. O gradiente é um vetor que aponta na direção de maior crescimento da função; portanto, ao dar um passo na direção oposta ao gradiente, o algoritmo \"desce\" a curva, aproximando-se iterativamente do ponto de mínimo. O gradiente é, por definição, o vetor das derivadas parciais da função.\n",
    "\n",
    "✅ Newton Raphson (Método de Newton)\n",
    "É um algoritmo para encontrar as raízes de uma função (ou seja, os pontos onde f(x)=0). Ele utiliza a primeira derivada da função para encontrar a tangente à curva em um ponto e usa a intersecção dessa tangente com o eixo x como a próxima aproximação. A fórmula de iteração é x \n",
    "n+1\n",
    "​\n",
    " =x \n",
    "n\n",
    "​\n",
    " − \n",
    "f \n",
    "′\n",
    " (x \n",
    "n\n",
    "​\n",
    " )\n",
    "f(x \n",
    "n\n",
    "​\n",
    " )\n",
    "​\n",
    " , que depende diretamente da derivada f \n",
    "′\n",
    " (x \n",
    "n\n",
    "​\n",
    " ). Em otimização, ele é usado para encontrar o mínimo de uma função ao encontrar a raiz de sua primeira derivada.\n",
    "\n",
    "❌ CART (Classification and Regression Trees)\n",
    "As árvores de decisão, como o CART, funcionam de maneira diferente. Elas não otimizam uma função de custo contínua usando derivadas. Em vez disso, o algoritmo constrói a árvore de forma \"gananciosa\" (greedy), fazendo divisões sequenciais nos dados. Em cada etapa, ele testa todas as possíveis divisões em todas as variáveis e escolhe aquela que resulta na maior \"pureza\" dos nós filhos, medida por métricas como o Índice Gini ou a Entropia (para classificação) ou a redução do Erro Quadrático Médio (para regressão). Esse processo é combinatório e de contagem, não envolvendo o cálculo de gradientes ou derivadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dada uma base de dados com uma variável resposta $y$ e um conjunto de variáveis explicativas. Considere uma estrutura de um modelo de regressão. Explique com suas palavras por que não é possível obter parâmetros que forneçam um erro quadrático médio (EQM) menor que o obtido com estimadores de mínimos quadrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A Intuição: O Propósito do Método\n",
    "Imagine que você tem uma tarefa muito específica: encontrar o ponto mais baixo em um vale. O método dos Mínimos Quadrados é como um conjunto de instruções que foi criado com um único e exclusivo propósito: guiar você até o ponto mais baixo e parar lá.\n",
    "\n",
    "Nesse cenário:\n",
    "\n",
    "O \"vale\" é a superfície de todos os possíveis Erros Quadráticos Médios (EQM) que você pode obter.\n",
    "\n",
    "Sua \"localização\" no vale é determinada pelos parâmetros (coeficientes β) do seu modelo.\n",
    "\n",
    "A \"altitude\" é o valor do EQM.\n",
    "\n",
    "O método dos Mínimos Quadrados é, por sua própria definição, o procedimento matemático que encontra os exatos parâmetros (β \n",
    "0\n",
    "​\n",
    " ,β \n",
    "1\n",
    "​\n",
    " ,...) que correspondem ao fundo do vale, ou seja, ao ponto de menor altitude possível.\n",
    "\n",
    "Portanto, não é possível obter um EQM menor que o de Mínimos Quadrados porque o método foi literalmente desenhado para fazer uma única coisa: encontrar o EQM mínimo. Qualquer outro conjunto de parâmetros, por definição, estaria em um ponto mais alto do vale.\n",
    "\n",
    "2. A Explicação Matemática (sem complicação)\n",
    "O Erro Quadrático Médio (EQM) é calculado como:\n",
    "\n",
    "EQM= \n",
    "n\n",
    "1\n",
    "​\n",
    "  \n",
    "i=1\n",
    "∑\n",
    "n\n",
    "​\n",
    " (y \n",
    "i\n",
    "​\n",
    " − \n",
    "y\n",
    "^\n",
    "​\n",
    "  \n",
    "i\n",
    "​\n",
    " ) \n",
    "2\n",
    " \n",
    "\n",
    "Onde y \n",
    "i\n",
    "​\n",
    "  é o valor real e  \n",
    "y\n",
    "^\n",
    "​\n",
    "  \n",
    "i\n",
    "​\n",
    "  é o valor previsto pelo modelo.\n",
    "\n",
    "O método de Mínimos Quadrados (Ordinary Least Squares - OLS) trata o EQM (ou a Soma dos Erros Quadráticos, que é proporcional) como uma função dos parâmetros do modelo. Pense no EQM como f(β \n",
    "0\n",
    "​\n",
    " ,β \n",
    "1\n",
    "​\n",
    " ,...).\n",
    "\n",
    "Para encontrar o valor mínimo de qualquer função, o cálculo nos ensina a usar derivadas. O que o OLS faz é:\n",
    "\n",
    "Calcula as derivadas parciais da função do EQM em relação a cada um dos parâmetros (β \n",
    "0\n",
    "​\n",
    " ,β \n",
    "1\n",
    "​\n",
    " , etc.).\n",
    "\n",
    "Iguala todas essas derivadas a zero.\n",
    "\n",
    "Resolve o sistema de equações resultante para encontrar os valores dos parâmetros.\n",
    "\n",
    "O ponto onde todas as derivadas são zero é, por definição matemática, um ponto crítico (neste caso, o mínimo global, pois a função é convexa). Não existe outro ponto com um valor menor, pois qualquer outro ponto teria uma \"inclinação\" (derivada) diferente de zero, indicando que ainda há uma direção para \"descer\" e diminuir o erro.\n",
    "\n",
    "3. A Ressalva Importante: Dados de Treino vs. Dados de Teste\n",
    "Tudo o que foi dito acima é absolutamente verdadeiro para a base de dados que foi usada para treinar o modelo (os dados \"vistos\" pelo algoritmo).\n",
    "\n",
    "No entanto, no mundo real, estamos mais interessados em como o modelo performa em dados novos e nunca vistos. E aqui a história muda.\n",
    "\n",
    "Modelos como a Regressão Ridge ou Lasso intencionalmente encontram parâmetros que resultam em um EQM um pouco maior nos dados de treino. Eles fazem isso adicionando uma penalidade aos parâmetros. Em troca desse pequeno sacrifício no treino, eles geralmente conseguem um EQM menor nos dados de teste, pois se tornam menos sensíveis aos ruídos específicos dos dados de treino (um fenômeno chamado de overfitting).\n",
    "\n",
    "Em resumo: Para os dados que você usou para ajustar o modelo, os Mínimos Quadrados são imbatíveis por definição. Mas quando o objetivo é generalizar para novos dados, outros métodos podem ser superiores, mesmo que \"percam\" para o OLS nos dados originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
